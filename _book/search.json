[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science Through Examples",
    "section": "",
    "text": "Este es un sitio web, a modo de libro, donde se pretende recopilar información sobre conceptos y métodos relacionados con Ciencia de Datos a través de ejemplos sencillos.\nSitio web hecho con Quarto."
  },
  {
    "objectID": "p-values/p-values.html#ejemplo",
    "href": "p-values/p-values.html#ejemplo",
    "title": "p-values",
    "section": "Ejemplo",
    "text": "Ejemplo\nUn fabricante de bombillas establece que la duración promedio de sus bombillas es de 10.000 horas. Un auditor externo propone que la duración promedio de las bombillas es en realidad menor de las 10.000 horas.\nSe sabe que la duración promedio de una bombilla se distribuye normalmente con \\(\\sigma^2 = 1000\\).\nEl auditor consiguió una muestra aleatoria de 28 bombillas y obtuvo una duración promedio de 9500 horas.\nRealice una prueba de hipótesis de acuerdo a lo planteado por el auditor externo."
  },
  {
    "objectID": "p-values/p-values.html#definición",
    "href": "p-values/p-values.html#definición",
    "title": "p-values",
    "section": "Definición",
    "text": "Definición\nSea:\n\nX = Duración de una bombilla de la población de interés"
  },
  {
    "objectID": "p-values/p-values.html#hipótesis",
    "href": "p-values/p-values.html#hipótesis",
    "title": "p-values",
    "section": "Hipótesis",
    "text": "Hipótesis\n\\[ H_0: \\mu = 10.000 \\ \\text{horas}  \n    \\ \\ \\ \\ \\\n   H_A: \\mu < 10.000 \\ \\text{horas}\\]"
  },
  {
    "objectID": "p-values/p-values.html#estadístico-de-prueba",
    "href": "p-values/p-values.html#estadístico-de-prueba",
    "title": "p-values",
    "section": "Estadístico de Prueba",
    "text": "Estadístico de Prueba\nPara este caso, se tiene que:\n\n\\(X\\) se distribuye normalmente.\n\\(\\sigma^2 = 1000\\)\n\\(n = 28\\)\n\nEl estadístico de prueba es:\n\\[ Z_c =  \\dfrac{\\overline{X}-\\mu_0}{\\dfrac{\\sigma}{\\sqrt{n}}}\\]\n\n\nShow the code\nZ_c <- (9500 - 10000) / (1500 / sqrt(28))\n\n\n\\[ Z_c = \\dfrac{9500-10000}{\\dfrac{1500}{\\sqrt{28}}} = -1.7638\\]"
  },
  {
    "objectID": "p-values/p-values.html#valor-p",
    "href": "p-values/p-values.html#valor-p",
    "title": "p-values",
    "section": "Valor p",
    "text": "Valor p\nEs la probabilidad de obtener un valor para el estadístico de prueba que sea igual o más extremo de contradictorio a \\(H_0\\) que el valor obtenido, suponiendo que \\(H_0\\) es verdadera.\n\\[ \\text{valor p} =  P(Z \\leq Z_c) =P(Z < Z_c)  \\]\nPara este caso:\n\n\nShow the code\np <- pnorm(Z_c)\n\n\n\\[ \\text{valor p} = P(Z < Z_c) = 0.0389\\]\n\n\nShow the code\nggplot(data.frame(x = c(-3, 3)), aes(x)) +\n   stat_function(fun = dnorm,\n                 geom = \"line\",\n                 xlim = c(-3, 3)) +\n   stat_function(fun = dnorm,\n                 geom = \"area\",\n                 fill = \"blue\",\n                 xlim = c(-3, Z_c)) +\n   geom_vline(xintercept = Z_c, colour=\"red\", linetype = \"longdash\") +\n   annotate(\"text\", label = \"Z_c\", x = -2, y = 0.3) +\n   annotate(\"text\", label = \"Valores igual o \\n más extremos de \\n contradictorio \\n que Z_c a la \\n hipótesis nula\", x = -2.5, y = 0.2) +\n    annotate(\"text\", label = \"El área en azul \\n representa tal \\n probabilidad\", x = -2.5, y = 0.1, color = \"blue\") +\n   geom_segment(\n       aes(x = Z_c, y = 0, xend = -3, yend = 0), \n       color = \"red\",\n       size = 1.2,\n       arrow = arrow(length = unit(4, \"mm\"))\n       ) +\n   xlim(-3, 3) +\n   labs(x = \"Z\", y = \"density\")\n\n\n\n\n\n¿Por qué se rechaza la hipótesis nula para valores bajos de \\(H_0\\)?\nEl valor se calcula suponiendo que la hipótesis nula es verdadera.\nPor ejemplo, para este caso, suponiendo que \\(\\mu = 10000 \\ \\text{horas}\\), la probabilidad de que \\(Z_c < -1.7638\\) es de \\(0.0389\\) (valor p).\nEntre más pequeño es valor p, más contradictorios son los datos a \\(H_0\\).\nEn este caso, con cualquier nivel de significancia (\\(\\alpha\\)) mayor a \\(0.0389\\), se rechaza la hipótesis nula.\nDe aquí se deriva una definición alternativa para el valor p (o nivel de significación observado): “es el nivel de significancia más pequeño al cual \\(H_0\\) sería rechazada”."
  },
  {
    "objectID": "01-p-values/p-values.html#ejemplo",
    "href": "01-p-values/p-values.html#ejemplo",
    "title": "Valor p",
    "section": "Ejemplo",
    "text": "Ejemplo\nUn fabricante de bombillas establece que la duración promedio de sus bombillas es de 10.000 horas. Un auditor externo propone que la duración promedio de las bombillas es en realidad menor de las 10.000 horas.\nSe sabe que la duración promedio de una bombilla se distribuye normalmente con \\(\\sigma^2 = 1000\\).\nEl auditor consiguió una muestra aleatoria de 28 bombillas y obtuvo una duración promedio de 9500 horas.\nRealice una prueba de hipótesis de acuerdo a lo planteado por el auditor externo."
  },
  {
    "objectID": "01-p-values/p-values.html#definición",
    "href": "01-p-values/p-values.html#definición",
    "title": "Valor p",
    "section": "Definición",
    "text": "Definición\nSea:\n\nX = Duración de una bombilla de la población de interés"
  },
  {
    "objectID": "01-p-values/p-values.html#hipótesis",
    "href": "01-p-values/p-values.html#hipótesis",
    "title": "Valor p",
    "section": "Hipótesis",
    "text": "Hipótesis\n\\[ H_0: \\mu = 10.000 \\ \\text{horas}  \n    \\ \\ \\ \\ \\\n   H_A: \\mu < 10.000 \\ \\text{horas}\\]"
  },
  {
    "objectID": "01-p-values/p-values.html#estadístico-de-prueba",
    "href": "01-p-values/p-values.html#estadístico-de-prueba",
    "title": "Valor p",
    "section": "Estadístico de Prueba",
    "text": "Estadístico de Prueba\nPara este caso, se tiene que:\n\n\\(X\\) se distribuye normalmente.\n\\(\\sigma^2 = 1000\\)\n\\(n = 28\\)\n\nEl estadístico de prueba es:\n\\[ Z_c =  \\dfrac{\\overline{X}-\\mu_0}{\\dfrac{\\sigma}{\\sqrt{n}}}\\]\n\n\nShow the code\nZ_c <- (9500 - 10000) / (1500 / sqrt(28))\n\n\n\\[ Z_c = \\dfrac{9500-10000}{\\dfrac{1500}{\\sqrt{28}}} = -1.7638\\]"
  },
  {
    "objectID": "01-p-values/p-values.html#valor-p",
    "href": "01-p-values/p-values.html#valor-p",
    "title": "Valor p",
    "section": "Valor p",
    "text": "Valor p\nEs la probabilidad de obtener un valor para el estadístico de prueba que sea igual o más extremo de contradictorio a \\(H_0\\) que el valor obtenido, suponiendo que \\(H_0\\) es verdadera.\n\\[ \\text{valor p} =  P(Z \\leq Z_c) =P(Z < Z_c)  \\]\nPara este caso:\n\n\nShow the code\np <- pnorm(Z_c)\n\n\n\\[ \\text{valor p} = P(Z < Z_c) = 0.0389\\]\n\n\nShow the code\nggplot(data.frame(x = c(-3, 3)), aes(x)) +\n   stat_function(fun = dnorm,\n                 geom = \"line\",\n                 xlim = c(-3, 3)) +\n   stat_function(fun = dnorm,\n                 geom = \"area\",\n                 fill = \"blue\",\n                 xlim = c(-3, Z_c)) +\n   geom_vline(xintercept = Z_c, colour=\"red\", linetype = \"longdash\") +\n   annotate(\"text\", label = \"Z_c\", x = -2, y = 0.3) +\n   annotate(\"text\", label = \"Valores igual o \\n más extremos de \\n contradictorio \\n que Z_c a la \\n hipótesis nula\", x = -2.5, y = 0.2) +\n    annotate(\"text\", label = \"El área en azul \\n representa tal \\n probabilidad\", x = -2.5, y = 0.1, color = \"blue\") +\n   geom_segment(\n       aes(x = Z_c, y = 0, xend = -3, yend = 0), \n       color = \"red\",\n       size = 1.2,\n       arrow = arrow(length = unit(4, \"mm\"))\n       ) +\n   xlim(-3, 3) +\n   labs(x = \"Z\", y = \"density\")\n\n\n\n\n\n¿Por qué se rechaza la hipótesis nula para valores bajos de \\(H_0\\)?\nEl valor se calcula suponiendo que la hipótesis nula es verdadera.\nPor ejemplo, para este caso, suponiendo que \\(\\mu = 10000 \\ \\text{horas}\\), la probabilidad de que \\(Z_c < -1.7638\\) es de \\(0.0389\\) (valor p).\nEntre más pequeño es valor p, más contradictorios son los datos a \\(H_0\\).\nEn este caso, con cualquier nivel de significancia (\\(\\alpha\\)) mayor a \\(0.0389\\), se rechaza la hipótesis nula.\nDe aquí se deriva una definición alternativa para el valor p (o nivel de significación observado): “es el nivel de significancia más pequeño al cual \\(H_0\\) sería rechazada”."
  },
  {
    "objectID": "02-r-squared/r-squared.html#librerías",
    "href": "02-r-squared/r-squared.html#librerías",
    "title": "R Cuadrado",
    "section": "Librerías",
    "text": "Librerías\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(dplyr)\noptions(scipen = 999)"
  },
  {
    "objectID": "02-r-squared/r-squared.html#ejemplo-1",
    "href": "02-r-squared/r-squared.html#ejemplo-1",
    "title": "R Cuadrado",
    "section": "Ejemplo 1",
    "text": "Ejemplo 1\nSe trata de explicar el precio de una casa (en miles de dólares) usando su tamaño (m2).\n\n\nShow the code\ncasas <- data.frame(price = c(120, 85, 67, 200, 110, 154), \n                    size = c(140, 92, 70, 150, 100, 120))\n\nmean_price <- mean(casas$price)\n\n\n\nTotal Sum of Squares\n\n\nShow the code\n# Dataframe for the segments of error\ncasas_segments_mean <- casas %>% mutate(x = size,\n                                        xend = size,\n                                        y = price,\n                                        yend = mean_price)\n\nggplot(casas) +\n  geom_point(aes(x = size, y = price), size = 3) +\n  geom_hline(yintercept = mean_price, color = \"red\", size = 1) +\n  geom_segment(data = casas_segments_mean, aes(x = x, y = y, xend = xend, yend = yend), \n               colour = \"blue\",\n               size = 1) \n\n\n\n\n\n\n\nSum of Squares of Residuals.\n\n\nShow the code\n#|message: false\n#|warning: false\nlin_mod <- lm(price ~ size, data = casas)\ncasas$predicted_price <- lin_mod$fitted.values\n\n\nggplot(casas, aes(x = size, y = price)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\", size = 1) +  \n  geom_segment(aes(xend = size, yend = predicted_price), color = \"darkgreen\", size = 1)\n\n\n`geom_smooth()` using formula 'y ~ x'"
  },
  {
    "objectID": "02-r-squared/r-squared.html#r-cuadrado-cálculo",
    "href": "02-r-squared/r-squared.html#r-cuadrado-cálculo",
    "title": "R Cuadrado",
    "section": "R cuadrado cálculo",
    "text": "R cuadrado cálculo\n\n\nShow the code\n# Total Sum of Squares. SUM of (y_i - y_mean)^2\nTSS <- sum((casas$price - mean_price)^2)\n\n# Sum of Squares of Residuals. SUM of (y_i - y_hat)^2\nRSS <- sum((casas$price - casas$predicted_price)^2)\n\n# R^2\nR_s <- (TSS - RSS)/(TSS)\n\n# Cálculo obtenido lm\nR_s_lm <- summary(lin_mod)$r.squared\n\nprint(c(R_s, R_s_lm))\n\n\n[1] 0.7544956 0.7544956\n\n\nNote que \\[ R^2 = \\dfrac{TSS-RSS}{TSS} = \\dfrac{TSS}{TSS} - \\dfrac{RSS}{TSS} \\]\n\\[ R^2 = 1 - \\dfrac{RSS}{TSS}\\]\nPara nuestro ejemplo:\n\\[ R^2 = \\dfrac{\n                \\overbrace{11647}^{\\text{VAR a explicar}}     \n                -\n                \\overbrace{2859}^{\\text{VAR NO explicada por modelo}}\n                }\n                {\n                \\underbrace{11647}_{\\text{VAR a explicar}}\n                }\n       = \\dfrac{\n                \\overbrace{11647 - 2859}^{\\text{VAR explicada por el modelo}}  \n                }\n                {\n                \\underbrace{11647}_{\\text{VAR a explicar}}\n                }\n      = 0.7545\\]\n\\(R^2\\) establece el porcentaje de variación en el precio (variable respuesta) que es explicado por el modelo, es decir, por el tamaño (variable explicativa). En nuestro ejemplo, el 75.45% de variación en el precio es explicado por el tamaño."
  },
  {
    "objectID": "04-classification-metrics/classification-metrics.html#matriz-de-confusión",
    "href": "04-classification-metrics/classification-metrics.html#matriz-de-confusión",
    "title": "Clasificación (métricas)",
    "section": "Matriz de confusión",
    "text": "Matriz de confusión\n\n\n\nMatriz de confusión\n\n\n\nSensitivity (sensitividad)\n\\[ \\text{Sensitivity} = \\dfrac{\\text{True Positives}}\n                              {\\text{True Positives + False Negatives}}  \\]\n\\[ \\text{Sensitivity}\n                      = p(\\text{Identificado con la enfermedad | Tiene la enfermedad }) \\]\nCuando se habla de “identificado con la enfermedad”, esto supone que el modelo ha predicho que tiene la enfermedad.\nLa sensitividad establece qué % de los pacientes con la enfermedad son correctamente clasificados. En un test médico como el de covid, una alta sensitividad implica que si el paciente tiene covid, el test tiene alta capacidad de detectarlo.\nEs la respuesta a la siguiente pregunta:\nSi un paciente tiene la enfermedad, ¿cuál es la probabilidad de que sea detectada?\n\n\nSpecificity (especificidad)\n\\[\\text{Specificity} = \\dfrac{\\text{True Negatives}}\n                              {\\text{True Negatives + False Positives}}\\]\n\\[\\text{Specificity}= p(\\text{Identificado sin la enfermedad | No tiene la enfermedad, ie, sano} )\\]\nLa especificidad establece el qué % de los pacientes sanos son correctamente clasificados. En un test médico como el de covid, una alta especificidad implica que si el paciente NO tiene covid, el test tiene una alta capacidad de producir un resultado NEGATIVO.\nEs la respuesta a la siguiente pregunta:\nSi un paciente está sano, ¿cuál es la probabilidad de que el resultado de la prueba sea NEGATIVO?\n\n\nError rate (Tasa de error)\n\\[ \\text{Error rate} = \\dfrac{\\text{False Positives + False Negatives}}{{n}}\\]\nLa tasa de error es el % de pacientes que son clasificados incorrectamente.\n\n\nAccuracy\n\\[ \\text{Accuracy} = \\dfrac{\\text{True Positives + True Negatives}}\n                           {n}\\]\nEs el % de pacientes que son clasificados correctamente.\n\n\nPrecision\n\\[ \\text{Precision} = \\dfrac{\\text{True Positives}}{\\text{True Positives + False Positives}}\\]\nDe los pacientes que fueron clasificados como enfermos, ¿qué % fue clasificado correctamente?"
  },
  {
    "objectID": "04-classification-metrics/classification-metrics.html#resumen",
    "href": "04-classification-metrics/classification-metrics.html#resumen",
    "title": "Clasificación (métricas)",
    "section": "Resumen",
    "text": "Resumen\n\n\n\n\n\n\n\n\n\nMétrica\nOtros nombres\nFórmula\nDescripción\n\n\n\n\nError rate\nES: Tasa de error\n\\(\\dfrac{FP+FN}{n}\\)\n% de pacientes que son clasificados incorrectamente\n\n\nAccuracy\nES: Precisión\n\\(\\dfrac{TP+TN}{n}\\)\n% de pacientes que son clasificados correctamente\n\n\nSensivity\nES: Sensitividad Recall True Positive Rate\n\\(\\dfrac{TP}{TP+FN} = \\dfrac{TP}{P}\\)\n% de pacientes con la enfermedad que son clasificados correctamente\n\n\nSpecificity\nES: Especificidad True Negative Rate\n\\(\\dfrac{TN}{FP+TN} = \\dfrac{TN}{N}\\)\n% de pacientes sin la enfermedad (sanos) que son clasificados correctamente\n\n\nPrecision\nPositive Predicted Value\n\\(\\dfrac{TP}{TP+FP}\\)\nDe los pacientes que fueron clasificados como enfermos, ¿qué % fue clasificado correctamente?\n\n\n\n\n\n\nDescripción\nDefinición\n\n\n\n\nTotal de pacientes\n\\(n = TP + FP + FN + TN\\)\n\n\nPacientes con la enfermedad\n\\(P = TP + FN\\)\n\n\nPacientes sin la enfermadad (sanos)\n\\(N = FP + TN\\)"
  },
  {
    "objectID": "03-bayes-theorem/bayes-theorem.html#ejemplo",
    "href": "03-bayes-theorem/bayes-theorem.html#ejemplo",
    "title": "Teorema de Bayes",
    "section": "Ejemplo",
    "text": "Ejemplo\nConsidere los siguientes eventos, en relación a la detección de correos electrónicos que son spam.\n\nContener la palabra ‘oferta’.\nSer SPAM.\n\nSe muestra la tabla de contigencia para 200 correos en relación a estos eventos:"
  },
  {
    "objectID": "03-bayes-theorem/bayes-theorem.html#representación-visual",
    "href": "03-bayes-theorem/bayes-theorem.html#representación-visual",
    "title": "Teorema de Bayes",
    "section": "Representación visual",
    "text": "Representación visual\nVisualmente, se puede representar como:\n\n\nCada cuadro representa un correo, en caso de contener la abreviación ‘Of’, esto indica que el correo es Spam."
  },
  {
    "objectID": "03-bayes-theorem/bayes-theorem.html#probabilidad-condicional",
    "href": "03-bayes-theorem/bayes-theorem.html#probabilidad-condicional",
    "title": "Teorema de Bayes",
    "section": "Probabilidad condicional",
    "text": "Probabilidad condicional\nLa pregunta natural que surge es la siguiente:\n¿cuál es la probabilidad de que un correo sea spam si contiene la palabra ‘oferta’?\nA partir de esta probabilidad, se podrá decidir si el correo se envía a la bandeja de Spam o no.\nUsando el Teorema de Bayes, se obtiene:\n\\[ P (\\text{Spam | Contiene la palabra oferta}) =\n    \\dfrac{P (\\text{Contiene la palabra oferta | Spam}) \\cdot P(\\text{Spam})}\n          {P (\\text{Contiene la palabra oferta})}\\]"
  },
  {
    "objectID": "03-bayes-theorem/bayes-theorem.html#derivación-visual",
    "href": "03-bayes-theorem/bayes-theorem.html#derivación-visual",
    "title": "Teorema de Bayes",
    "section": "Derivación visual",
    "text": "Derivación visual\nSupongamos que la representación visual es un rectángulo de área 1 representando probabilidad.\nTenemos que:\n\nDado que:\n\\[ P(\\text{Spam} \\cap \\text{Contiene la palabra oferta}) =\n    P(\\text{Contiene la palabra oferta|Spam}) \\cdot P(\\text{Spam}) \\]\n\\[ P(\\text{NO Spam} \\cap \\text{Contiene la palabra oferta}) =\n    P(\\text{Contiene la palabra oferta|NO Spam}) \\cdot P(\\text{NO Spam}) \\]\nSe reemplaza y se obtiene:\n\nEl resultado final es:\n\\[ P (\\text{Spam | Contiene la palabra oferta}) =\n    \\dfrac{P (\\text{Contiene la palabra oferta | Spam}) \\cdot P(\\text{Spam})}\n          {P (\\text{Contiene la palabra oferta})}\\]\nEste resultado coincide con lo ya antes mostrado por el Teorema de Bayes."
  },
  {
    "objectID": "03-bayes-theorem/bayes-theorem.html#actualización-de-probabilidad",
    "href": "03-bayes-theorem/bayes-theorem.html#actualización-de-probabilidad",
    "title": "Teorema de Bayes",
    "section": "Actualización de probabilidad",
    "text": "Actualización de probabilidad\nDe la derivación visual, se tiene que:\n\\[ P (\\text{Spam | Contiene la palabra oferta}) = \\dfrac{16}{16+32} = \\dfrac{16}{48} = \\dfrac{1}{3}\\]\nUsando el teorema de Bayes:\n\\[ P (\\text{Spam | Contiene la palabra oferta}) =\n    \\dfrac{P (\\text{Contiene la palabra oferta | Spam}) }\n          {P (\\text{Contiene la palabra oferta})} \\cdot P(\\text{Spam})\\]\nEsto se puede ver de la siguiente forma, \\(P(\\text{Spam | Contiene la palabra oferta})\\) es una escalación de \\(P(\\text{Spam})\\) por el factor \\(\\dfrac{P(\\text{Contiene la palabra oferta | Spam}) }{P (\\text{Contiene la palabra oferta})}\\)\nPara este ejemplo:\n\\[\\dfrac{P(\\text{Contiene la palabra oferta | Spam}) }{P (\\text{Contiene la palabra oferta})} = \\dfrac{16/40}{48/200} = 1.6667\\] Así:\n\\[ P (\\text{Spam | Contiene la palabra oferta}) = 1.6667 \\cdot P(\\text{Spam})\\]\nEs decir, la probabilidad de que sea Spam de aquellos correos con la palabra oferta es 1.6667 veces que la probabilidad (general) de que sea Spam.\n\\[ P (\\text{Spam | Contiene la palabra oferta}) = 1.6667 \\cdot \\dfrac{40}{200} = \\dfrac{1}{3}\\]\n\nEjemplo adicional\nConsidere el siguiente enunciado: “Cuando un equipo anota el primer gol, las probabilidades de victoria suben un 20%”, esto se traduce en:\n\\[ P(\\text{Ganar}|\\text{Anotar primer gol})= 1.20 \\times P(\\text{Ganar})\\] Por lo que:\n\\[ \\dfrac{P(\\text{Anotar primer gol|Ganar})}{P(\\text{Anotar primer gol})} = 1.20\\]"
  },
  {
    "objectID": "03-bayes-theorem/bayes-theorem.html#consideraciones-conceptuales",
    "href": "03-bayes-theorem/bayes-theorem.html#consideraciones-conceptuales",
    "title": "Teorema de Bayes",
    "section": "Consideraciones conceptuales",
    "text": "Consideraciones conceptuales\n\nSi A y B son independientes: \\(P(A \\cap B)=P(A) \\cdot P(B)\\)\nSi A y B no son independientes: \\(P(A \\cap B) = P(B|A) \\cdot P(A)\\)\n\\(P(B|A)= \\underbrace{P(B \\cap A|A)}_{\\text{A ya se dio}}\\neq \\underbrace{P(B \\cap A)}_{\\text{A NO se ha dado}}\\)"
  },
  {
    "objectID": "06-logistic-regression/logistic-regression.html#setup",
    "href": "06-logistic-regression/logistic-regression.html#setup",
    "title": "Regresión Logística",
    "section": "Setup",
    "text": "Setup\nEl siguiente ejemplo se realiza utilizando R.\nSi desea seguir el desarrollo del ejemplo, copie y ejecute la siguientes líneas de código:\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\n\nShow the code\n# TODO Change diabetes2.csv for a github link\ndiabetes <- read.csv(\"diabetes2.csv\") %>%\n            rename(Diabetes = Outcome,\n                   IMC = BMI)\n\n\n\n\nShow the code\nset.seed(99) # Se utiliza para obtener resultados reproducibles\ndiabetes_sample <- sample_n(diabetes, size = 100)"
  },
  {
    "objectID": "06-logistic-regression/logistic-regression.html#caso-de-estudio",
    "href": "06-logistic-regression/logistic-regression.html#caso-de-estudio",
    "title": "Regresión Logística",
    "section": "Caso de estudio",
    "text": "Caso de estudio\nSuponga que queremos predecir si una persona tiene o no diabetes, a partir de su índice de masa corporal (IMC).\nTenemos una variable, digamos Diabetes, que toma dos posibles valores: Sí (tiene diabetes) o No (tiene diabetes).\nUtilizaremos la siguientes codificación:\n\\[ \\text{Diabetes} = \\begin{cases}\n                      1, \\ \\ \\ \\ \\text{Sí} \\\\\n                      0, \\ \\ \\ \\ \\text{No}\n                      \\end{cases}\\]\nPara este ejemplo, hasta ahora, tenemos claridad respecto a lo siguiente:\n\nDiabetes es la variable que queremos predecir y tomas dos posibles valores: 1 (Sí) y 0 (No).\nIMC es la variable que nos ayudará a predecir si una persona tiene o no diabetes.\n\nUtilizaremos datos de Kaggle.\nInicialmente, grafiquemos una muestra de los datos:\n\n\nShow the code\nggplot(diabetes_sample) +\n  geom_point(aes(x = IMC, y = Diabetes))\n\n\n\n\n\nFigure 1: Diabetes vs IMC"
  },
  {
    "objectID": "06-logistic-regression/logistic-regression.html#modelo-estadístico",
    "href": "06-logistic-regression/logistic-regression.html#modelo-estadístico",
    "title": "Regresión Logística",
    "section": "Modelo estadístico",
    "text": "Modelo estadístico\nNote que en una regresión lineal se modela una variable, como por ejemplo:\n\nEl precio de una casa a partir de su tamaño y cantidad de habitaciones.\nLas ventas de una compañía a partir de la inversión en publicidad.\nEl salario de una persona a partir de su nivel de ecuación (básico, secundario o terciario).\n\nLas anteriores variables son cuantitativas y toman valores en un rango de números reales, por ejemplo, las ventas de una compañía pueden tomar cualquier valor entre 0 e infinito.\nAhora, en una regresión logística, a diferencia de una regresión lineal, se modela una probabilidad ya que la variable es categórica, pues solo toma dos valores 1 (Sí) y 0 (No).\nEn nuestro ejemplo, modelaremos la probabilidad de que una persona tenga Diabetes a partir del IMC:\n\\[ \\text{Pr(Diabetes = 1|IMC)}\\] Ahora, para ser más breves:\n\nEn vez de Diabetes utilizaremos la letra \\(Y\\) que se asocia con la variable que queremos predecir.\nEn vez de ICM, la letra \\(X\\):\n\n\\[ \\text{Pr}(Y = 1|X) \\]\nY abreviaremos \\(\\text{Pr}(Y=1|X)\\) como \\(p(X)\\).\nModelaremos \\(\\text{Pr(Diabetes = 1|IMC)} = \\text{Pr}(Y = 1|X) = p(X)\\).\nPara modelar a \\(p(X)\\) usamos la función logística, a diferencia de una función lineal que puede tomar cualquier valor en el intervalo \\((-\\infty, \\infty)\\), la función logística solo puede tomar valores en el intervalo \\((0, 1)\\), lo que la hace adecuada para modelar probabilidades:\n\\[ p(X) = \\dfrac{e^{\\beta_0 +\\beta_1X}}{1 + e^{\\beta_0 +\\beta_1X}}\\] Despejando \\(e^{\\beta_0 +\\beta_1X}\\), la anterior ecuación se puede reescribir como:\n\\[ \\underbrace{\\dfrac{p(X)}{1-p(X)}}_{\\text{Odds}} = e^{\\beta_0+\\beta_1X}  \\]\nTomando logaritmo a ambos lados:\n\\[ \\underbrace{\\log\\left(\\dfrac{p(X)}{1-p(X)}\\right)}_{\\text{Log Odds o Logit}} = \\beta_0 + \\beta_1X\\]"
  },
  {
    "objectID": "06-logistic-regression/logistic-regression.html#ajuste-del-modelo-en-r",
    "href": "06-logistic-regression/logistic-regression.html#ajuste-del-modelo-en-r",
    "title": "Regresión Logística",
    "section": "Ajuste del modelo en R",
    "text": "Ajuste del modelo en R\n\n\nShow the code\nreg_logistica <- glm(Diabetes ~ IMC,\n                     data = diabetes,\n                     family = \"binomial\")\n\nsummary(reg_logistica)\n\n\n\nCall:\nglm(formula = Diabetes ~ IMC, family = \"binomial\", data = diabetes)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.9209  -0.9178  -0.6838   1.2351   2.7244  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -3.68641    0.40896  -9.014  < 2e-16 ***\nIMC          0.09353    0.01205   7.761 8.45e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 993.48  on 767  degrees of freedom\nResidual deviance: 920.71  on 766  degrees of freedom\nAIC: 924.71\n\nNumber of Fisher Scoring iterations: 4\n\n\nSe tiene que:\n\n\\(\\beta_0\\) = \\(-3.68641\\)\n\\(\\beta_1\\) = \\(0.09353\\)\n\n\\[ \\hat{p}(X) = \\dfrac{e^{-3.68641 +0.09353X}}{1 + e^{-3.68641 +0.09353X}}\\]\nDe acuerdo al modelo ajustado, la probabilidad estimada de que una persona con \\(IMC = X\\) de 20 tenga diabetes es:\n\\[ \\hat{p}(X = 20) = \\dfrac{e^{-3.68641 +0.09353\\cdot 20}}{1 + e^{-3.68641 +0.09353\\cdot 20}} = 0.1399  = \\dfrac{e^{-1.81581}}{1+e^{-1.81581}}= 13.99\\%\\]\nEsta evaluación se puede hacer en R de la siguiente forma:\n\n\nShow the code\nnew_data = data.frame(IMC = 20)\n\npredict(reg_logistica, new_data, type = \"response\")\n\n\n        1 \n0.1399382 \n\n\nObserve que si utiliza el argumento type = \"link\" obtendremos \\(\\beta_0 + \\beta_1 X\\) ya que ea este término se le conoce como “énlace” o “función de énlace”.\nNote que para \\(X = 20\\):\n\\[  -3.68641 +0.09353\\cdot 20 = -1.81581\\]\n\n\nShow the code\npredict(reg_logistica, new_data, type = \"link\")\n\n\n        1 \n-1.815803 \n\n\n\n\nShow the code\nggplot(diabetes, aes(x = IMC, y = Diabetes)) +\n  geom_point() +\n  stat_smooth(method = \"glm\", se=FALSE, method.args = list(family = \"binomial\"))\n\n\n`geom_smooth()` using formula 'y ~ x'"
  },
  {
    "objectID": "06-logistic-regression/logistic-regression.html#interpretación-de-los-coeficientes",
    "href": "06-logistic-regression/logistic-regression.html#interpretación-de-los-coeficientes",
    "title": "Regresión Logística",
    "section": "Interpretación de los coeficientes",
    "text": "Interpretación de los coeficientes\nRecordemos que las Odds se definen como \\(\\dfrac{p(X)}{1-p(X)}\\)\nAsí:\n\\[ \\text{Odds}(X) = \\dfrac{p(X)}{1-p(X)} = e^{\\beta_0+\\beta_1X}\\]\nSi aumentamos una unidad en X:\n\\[ \\text{Odds}(X+1) = e^{\\beta_0+\\beta_1(X+1)}\\] Realizando el cociente:\n\\[ \\dfrac{\\text{Odds}(X+1)}{ \\text{Odds}(X)} = \\dfrac{e^{\\beta_0+\\beta_1(X+1)}}{e^{\\beta_0+\\beta_1(X)}} = e^{\\beta_1}=e^{0.09353} = 1.098044\\]\nPor cada unidad que incrementa el IMC, las Odds son un 9.8% más grandes, es decir, el cociente \\(\\dfrac{p(X)}{1-p(X)}\\) es 1.098 veces más grande."
  },
  {
    "objectID": "07-decision-trees/decision-trees.html#librerías",
    "href": "07-decision-trees/decision-trees.html#librerías",
    "title": "Decision Trees",
    "section": "Librerías",
    "text": "Librerías\n\n\nShow the code\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(knitr)\noptions(scipen = 999)"
  },
  {
    "objectID": "07-decision-trees/decision-trees.html#ejemplo",
    "href": "07-decision-trees/decision-trees.html#ejemplo",
    "title": "Decision Trees",
    "section": "Ejemplo",
    "text": "Ejemplo\nSe tienen datos sobre 10 pasajeros del titanic, se conoce:\n\nsurvive: Sobrevivió al hundimiento o no.\nclass: Primera o segunda clase.\nsex: Hombre o mujer.\n\n\n\nShow the code\n# Read data\ntitanic <- read.csv(\"titanic.csv\", sep = \";\")\n\nkable(titanic)\n\n\n\n\n\nclass\nsex\nsurvive\n\n\n\n\nfirst\nwoman\nyes\n\n\nfirst\nwoman\nyes\n\n\nfirst\nman\nyes\n\n\nfirst\nman\nyes\n\n\nfirst\nman\nno\n\n\nsecond\nwoman\nyes\n\n\nsecond\nwoman\nyes\n\n\nsecond\nman\nno\n\n\nsecond\nman\nno\n\n\nsecond\nman\nno"
  },
  {
    "objectID": "07-decision-trees/decision-trees.html#árbol-de-decisión",
    "href": "07-decision-trees/decision-trees.html#árbol-de-decisión",
    "title": "Decision Trees",
    "section": "Árbol de decisión",
    "text": "Árbol de decisión\n\n\nShow the code\n# Tree Model\ntree_model <- rpart(survive ~ class + sex, \n                    data = titanic,\n                    method = \"class\",  # Classification\n                    minsplit = 1)\n\n# Visualize\nprp(tree_model)"
  },
  {
    "objectID": "07-decision-trees/decision-trees.html#construcción-manual",
    "href": "07-decision-trees/decision-trees.html#construcción-manual",
    "title": "Decision Trees",
    "section": "Construcción manual",
    "text": "Construcción manual\n\nVariable como nodo principal\nPara decidir cuál de las variables debe ser la raíz (root) del árbol, se calcula la métrica Gini Impurity y se selecciona la variable con el menor valor.\nPara la variable sex:\n\nPara la variable class:\n\nNote que \\(\\text{Gini(sex) = 0.267 < Gini(class) = 0.4}\\), por lo que la raíz del árbol será la variable \\(\\text{sex}\\).\n\n\nSiguiente rama\nNote que cuando sex = men es falso, es decir, cuando se trata de una mujer, todos los casos conducen a que sobrevive, en otras palabras, tanto mujeres de primera como de segunda clase se salvan.\n\nAhora, cuando se trata de hombres, algunos sobreviven y otros no por lo que se sigue explorando con la variable clase:\n\nAsí, se obtiene el siguiente árbol, que coincide con el obtenido por la función rpart"
  },
  {
    "objectID": "07-decision-trees/decision-trees.html#gini-impurity-intuitivamente",
    "href": "07-decision-trees/decision-trees.html#gini-impurity-intuitivamente",
    "title": "Decision Trees",
    "section": "Gini Impurity (intuitivamente)",
    "text": "Gini Impurity (intuitivamente)"
  }
]